import sys, os, time
import subprocess
import threading
import cv2
from PyFasterRCNN import PyFasterRCNN

curr_path = os.path.dirname(os.path.abspath(os.path.expanduser(__file__)))
sys.path.append("~/mxnet/amalgamation/python/")
sys.path.append("~/mxnet/python/")

from mxnet_predict import Predictor, load_ndarray_file
import mxnet as mx
import logging
import numpy as np
from skimage import io, transform
# Load the pre-trained model
prefix = "./gender-0"
num_round = 125
batch_size = 20
if len(sys.argv) >1:
    num_round = int(sys.argv[1])
symbol_file = "%s-symbol.json" % prefix
param_file = "%s-%s.params" % (prefix,str(num_round).zfill(4))
predictor = Predictor(open(symbol_file).read(), open(param_file).read(), {'data':(batch_size , 3, 224, 224)},'gpu',0)
mean_img = load_ndarray_file(open("./mean.bin").read())["mean_img"]

synset = [l.strip() for l in open('./labels.txt').readlines()]

def PreprocessImage(batchs, index, path, show_img=False):
    # load image
    img = io.imread(path)
    #print("Original Image Shape: ", img.shape)
    # we crop image from center
    short_egde = min(img.shape[:2])
    yy = int((img.shape[0] - short_egde) / 2)
    xx = int((img.shape[1] - short_egde) / 2)
    crop_img = img[yy : yy + short_egde, xx : xx + short_egde]
    # resize to 224, 224
    resized_img = transform.resize(crop_img, (224, 224))
    if show_img:
        io.imshow(resized_img)
    # convert to numpy.ndarray
    sample = np.asarray(resized_img) * 255
    # swap axes to make image from (224, 224, 3) to (3, 224, 224)
    sample = np.swapaxes(sample, 0, 2)
    sample = np.swapaxes(sample, 1, 2)

    # sub mean
    normed_img = sample - mean_img
    normed_img.resize(1, 3, 224, 224)
    
    batchs[index] = normed_img
    

if __name__=="__main__":
    pyFasterRCNN = PyFasterRCNN()
    # use camera 0    
    capture=cv2.VideoCapture(0)
    #capture.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH,640)
    #capture.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT,360)
    capture.set(cv2.CAP_PROP_FRAME_WIDTH,640)
    capture.set(cv2.CAP_PROP_FRAME_HEIGHT,360)
        
    cv2.namedWindow("Face Detection Result Viewer")

    print capture.isOpened()
    
    num=0
    while True:
        ret, img=capture.read()
        if ret:
            result = pyFasterRCNN.detectRaw(img)
            js=json.load(result)
            nums=result["obj_num"]
            boxes =         result["objects"]
            cv2.imshow("Face Detection Result Viewer",img)
            
            # Get preprocessed batch (single image batch)
            start = time.time()
            predictor.forward(data=img)
            prob = predictor.get_output(0)
            pred = np.argsort(prob[0])[::-1]
            # Get top1 label
            top1 = synset[pred[0]],prob[0][pred[0]]
            print  "top-1", top1[0], top1[1] 
            print "time elapsed: %f."%((time.time()-start))
            num=num+1
            key=cv2.waitKey(10)&0xFF
            if key==ord('q') or key==27:
                break
        else:
            continue
    capture.release()
    cv2.destroyAllWindows() 
